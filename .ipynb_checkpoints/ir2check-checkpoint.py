{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e3785-765c-46a7-891a-271780de6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import math\n",
    "import string\n",
    "import os\n",
    "import glob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "Dictionary = {}  # Contains term frequencies for each word in each document\n",
    "DocVectors = {}  # Contains TF-IDF vectors for each document\n",
    "\n",
    "def FileRead():\n",
    "    # Function to read files, preprocess text, and build the dictionary\n",
    "    \n",
    "    Folder = 'ResearchPapers'\n",
    "    Pattern = '*.txt' \n",
    "    FList = glob.glob(os.path.join(Folder, Pattern)) #Finding all Files in the given Folder \n",
    "    \n",
    "    for Path in FList: \n",
    "        with open(Path, 'r') as file: \n",
    "            FileContents = file.read() #Reading File text\n",
    "            FileContents = FileContents.lower()\n",
    "            File_name = Path.strip(\"ResearchPapers\\\\.txt\")\n",
    "            FileContents = PunctuationRemove(FileContents)# Removing Punctuations\n",
    "            FileContents = FileContents.split() # Tokenizing string\n",
    "            Stemmer = PorterStemmer()\n",
    "            FileStem = []\n",
    "            #Applying Stemming to all the tokens\n",
    "            for words in list(FileContents):\n",
    "                FileStem.append(Stemmer.stem(words))\n",
    "            File_name = int(File_name)\n",
    "            Dictionary = DictionaryBuilder(FileStem,File_name)\n",
    "            Dictionary = sorted(Dictionary.items()) # Sorting the Dictionary by tokens\n",
    "            Dictionary = dict(Dictionary)\n",
    "    \n",
    "    # Initializing all Document Vectors with 0 for every word\n",
    "    for i in range(1,26):\n",
    "         DocVectors[i] = [0] * len(Dictionary)\n",
    "    \n",
    "    return Dictionary\n",
    "\n",
    "def PunctuationRemove(File):\n",
    "    # Function to remove punctuation marks from text\n",
    "    File = File.replace('-', ' ')  # Replacing hyphens with spaces\n",
    "    File = File.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return File\n",
    "\n",
    "def DictionaryBuilder(File, File_Name):\n",
    "    # Function to build the dictionary with term frequencies\n",
    "    \n",
    "    Stop = open('Stopword-List.txt', 'r')\n",
    "    StopContents = Stop.read()\n",
    "    StopContents = StopContents.split()\n",
    "    \n",
    "    # Building dictionary\n",
    "    for word in File: \n",
    "        if word not in StopContents:\n",
    "            if word not in Dictionary:  # First time a word is added to dictionary\n",
    "                Dictionary[word] = {}\n",
    "                Dictionary[word][File_Name] = 1  # Setting term frequency for the document to 1\n",
    "            else:\n",
    "                if File_Name not in Dictionary[word]:\n",
    "                    Dictionary[word][File_Name] = 1  # Setting term frequency for the document to 1\n",
    "                else:\n",
    "                    Dictionary[word][File_Name] += 1  # Incrementing term frequency\n",
    "    \n",
    "    return Dictionary\n",
    "\n",
    "def BuildDocumentVectors():\n",
    "    # Function to build TF-IDF vectors for each document\n",
    "    \n",
    "    for Index, Key in enumerate(Dictionary): \n",
    "        for DocKeys in DocVectors.keys(): \n",
    "            if DocKeys in Dictionary[Key]:\n",
    "                DocFreq = len(Dictionary[Key]) \n",
    "                InvertedDocFreq = round(math.log(len(DocVectors) / DocFreq, 10), 2)  # Calculating IDF\n",
    "                TfIdf = InvertedDocFreq * Dictionary[Key][DocKeys]  # Calculating TF-IDF\n",
    "                DocVectors[DocKeys][Index] = TfIdf\n",
    "\n",
    "def QueryProcessor(Query):\n",
    "    # Function to process query text and convert it into a vector\n",
    "    \n",
    "    Query = Query.split()\n",
    "    Query = QueryStemmer(Query)  # Stemming query words\n",
    "    QueryVector = [0] * len(Dictionary)  # Initializing query vector\n",
    "    QueryDict = {}\n",
    "    \n",
    "    # Building dictionary for query\n",
    "    for word in Query: \n",
    "        if word not in QueryDict:\n",
    "            QueryDict[word] = 1\n",
    "        else:\n",
    "            QueryDict[word] += 1\n",
    "    \n",
    "    # Calculating TF-IDF for query vector\n",
    "    for Index, Key in enumerate(Dictionary): \n",
    "        if Key in QueryDict:\n",
    "            DocFreq = len(Dictionary[Key])\n",
    "            InvertedDocFreq = math.log(len(DocVectors) / DocFreq, 10)\n",
    "            TfIdf = InvertedDocFreq * QueryDict[Key]\n",
    "            QueryVector[Index] = TfIdf\n",
    "    \n",
    "    return QueryVector\n",
    "\n",
    "def QueryStemmer(Query):\n",
    "    # Function to stem words in query\n",
    "    \n",
    "    StemQuery = []\n",
    "    Stop = open('Stopword-List.txt', 'r')\n",
    "    StopContents = Stop.read()\n",
    "    StopContents = StopContents.split()\n",
    "    Stemmer = PorterStemmer()\n",
    "    Query = [Val for Val in Query if Val not in StopContents]\n",
    "    \n",
    "    # Stemming query words\n",
    "    for word in Query:\n",
    "        StemQuery.append(Stemmer.stem(word))\n",
    "    \n",
    "    return StemQuery  \n",
    "\n",
    "def EucDist(Vector):\n",
    "    # Function to calculate Euclidean distance for a vector\n",
    "    \n",
    "    Sum = 0\n",
    "    for i in Vector:\n",
    "        Sum += i ** 2\n",
    "    return math.sqrt(Sum)\n",
    "\n",
    "def Solver(Query):\n",
    "    # Function to solve the query and retrieve relevant documents\n",
    "    \n",
    "    ResultList = []\n",
    "    QueryEucDist = EucDist(Query)  # Calculating Euclidean length for the query\n",
    "    \n",
    "    if QueryEucDist == 0: \n",
    "        return ResultList  # Return empty list if the query vector is all zeros\n",
    "    \n",
    "    for Doc in DocVectors.keys():\n",
    "        Cosine = 0\n",
    "        DotProduct = 0\n",
    "        DocEucDist = EucDist(DocVectors[Doc])  # Calculating Euclidean length for a given document\n",
    "        \n",
    "        if DocEucDist == 0: \n",
    "            continue  # Skip calculation if the document vector is all zeros\n",
    "        \n",
    "        for i in range(0, len(Dictionary)):\n",
    "            if Query[i] == 0 or DocVectors[Doc][i] == 0: \n",
    "                continue  # Skip calculation if one of the TF-IDFs is zero\n",
    "            else:\n",
    "                DotProduct += Query[i] * DocVectors[Doc][i]\n",
    "        \n",
    "        Cosine = DotProduct / (QueryEucDist * DocEucDist)\n",
    "        \n",
    "        if Cosine > 0.05:  # Threshold\n",
    "            ResultList.append((Doc, Cosine))\n",
    "    \n",
    "    # Sort results according to cosine value\n",
    "    ResultList = sorted(ResultList, key=lambda x:-x[1])  \n",
    "    return ResultList\n",
    "\n",
    "def on_click():\n",
    "    # Function to handle query button click event\n",
    "    \n",
    "    query_text = query_entry.get(\"1.0\", tk.END).strip()\n",
    "    if query_text:\n",
    "        Query = QueryProcessor(query_text)\n",
    "        results = Solver(Query)\n",
    "        result_text.delete('1.0', tk.END)\n",
    "        for result in results:\n",
    "            result_text.insert(tk.END, f\"Document: {result[0]}, Cosine Similarity: {result[1]}\\n\")\n",
    "\n",
    "# Reading files, building dictionaries, and constructing document vectors\n",
    "Dictionary = FileRead()\n",
    "BuildDocumentVectors()\n",
    "\n",
    "# Creating GUI using tkinter\n",
    "root = tk.Tk()\n",
    "root.title(\"Document Search Engine\")\n",
    "\n",
    "root.configure(bg=\"#000000\")\n",
    "\n",
    "query_frame = tk.Frame(root)\n",
    "query_frame.pack(pady=10)\n",
    "\n",
    "query_label = tk.Label(query_frame, text=\"Enter your Query:\", bg=\"#000000\", fg=\"#FFFFFF\")  # Set text and background color\n",
    "query_label.pack(side=tk.LEFT)\n",
    "\n",
    "query_entry = tk.Text(query_frame, height=5, width=100, bg=\"#FFFFFF\", fg=\"#000000\")  # Set text and background color\n",
    "query_entry.pack(side=tk.LEFT)\n",
    "\n",
    "query_button = tk.Button(query_frame, text=\"Search query\", command=on_click, bg=\"#FFFFFF\", fg=\"#000000\")  # Set button color\n",
    "query_button.pack(side=tk.LEFT)\n",
    "\n",
    "result_text = scrolledtext.ScrolledText(root, width=80, height=20, wrap=tk.WORD, bg=\"#000000\", fg=\"#FFFFFF\")  # Set text and background color\n",
    "result_text.pack(padx=10, pady=10)\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
